{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from data_util import *\n",
    "from metric_util import *\n",
    "from train_util import *\n",
    "from model import *\n",
    "\n",
    "import torch \n",
    "import pickle\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet18\n",
    "#os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import sys\n",
    "sys.path.append('./PyGCL')\n",
    "import GCL.losses as L\n",
    "from GCL.models import DualBranchContrast\n",
    "from GCL.eval import get_split, LREvaluator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    # meta config\n",
    "    'dataset_name': 'celeba',\n",
    "    'sens_name': 'gender',\n",
    "    'conditional': False,\n",
    "    'debias': False,\n",
    "    'adversarial': False,\n",
    "    # tunable config\n",
    "    'batch_size': 256 * 2,\n",
    "    'hidden_dim': 240,\n",
    "    'drop_prob': 0.2,\n",
    "    'cond_temp': 1.0/200,\n",
    "    'debias_temp': 1.0/30,\n",
    "    'debias_ratio': 4,\n",
    "    'lr': 0.00005,\n",
    "    'tau': 0.1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some more config setting\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "dataset_name = config['dataset_name']\n",
    "sens_name = config['sens_name']\n",
    "sens_num = 2 if sens_name=='gender' else 1\n",
    "TASK_TYPE = 'regression' if dataset_name=='crimes' else 'classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset...\n",
    "dataset = get_dataset(dataset_name, sens_name)\n",
    "#x = dataset[:][0]\n",
    "#sens = dataset[:][2]\n",
    "x, sens = get_samples(dataset, num=1000)\n",
    "dataloader = DataLoader(dataset, batch_size=config['batch_size'], shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare model config\n",
    "#input_dim = dataset[0][0].shape[-1]\n",
    "hidden_dim = config['hidden_dim'] if config['dataset_name'] != 'celeba' else 1000\n",
    "sens_dim = dataset.sens_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "main_encoder = RES()\n",
    "sens_encoder = MLP(sens_dim,hidden_dim)\n",
    "adv_model = Adv_sens(sens_num=sens_num, hidden_dim=hidden_dim)\n",
    "\n",
    "aug = transforms.Compose([transforms.RandomCrop(size=RESIZE), transforms.ColorJitter(),\n",
    "                         transforms.Grayscale(num_output_channels=3), transforms.RandomHorizontalFlip(),\n",
    "                         transforms.RandomVerticalFlip()])#FeatureDrop(drop_prob=config['drop_prob'])\n",
    "\n",
    "encoder_model = Encoder(main_encoder = main_encoder, augmentor = aug, sens_encoder = sens_encoder, adv_model=adv_model)\n",
    "encoder_model = encoder_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "contrast_model = DualBranchContrast(loss=L.FairInfoNCE(tau=config['tau']), mode='G2G').to(device)\n",
    "optim = Adam(encoder_model.parameters(), lr=config['lr'])\n",
    "\n",
    "performance_list = []\n",
    "hist_gdp_list = []\n",
    "max_gdp_list = []\n",
    "kernel_gdp_list = []\n",
    "\n",
    "epoch = 100\n",
    "with tqdm(total=epoch, desc='(T)') as pbar:\n",
    "    for epoch in range(1, epoch+1):\n",
    "        encoder_model = encoder_model.to(device)\n",
    "        loss_result = train(encoder_model = encoder_model, contrast_model=contrast_model,\n",
    "                                         dataloader=dataloader, optimizer = optim,\n",
    "                                         conditional=config['conditional'],debias=config['debias'], adversarial=config['adversarial'] if epoch%5==0 else False,\n",
    "                                         cond_temp = config['cond_temp'],\n",
    "                                         debias_temp = config['debias_temp'],\n",
    "                                         debias_ratio = config['debias_ratio'])\n",
    "        pbar.set_postfix({'loss': loss_result['loss'], \n",
    "                          'conditional_loss':loss_result['conditional_loss'], \n",
    "                          'debias_loss': loss_result['debias_loss'],\n",
    "                          'adv_loss': loss_result['adv_loss']})\n",
    "        pbar.update()\n",
    "        \n",
    "        if epoch % 1 == 0:\n",
    "            print(loss_result)\n",
    "            result, evaluator = test(encoder_model, dataloader, evaluator=LREvaluator(task=TASK_TYPE))\n",
    "            classifier = result['classifier']\n",
    "            \n",
    "            # performance \n",
    "            performance = result['mae'] if dataset_name=='crimes' else result['auc']\n",
    "            print('performance: ', performance)\n",
    "            performance_list.append(performance)\n",
    "\n",
    "            # fairness\n",
    "            hist_gdp = gdp(mode='hist', task=TASK_TYPE, hist_num=1000, x = x, sens = sens, encoder_model = encoder_model, classifier = classifier)\n",
    "            print('hist gdp: ', hist_gdp)\n",
    "            hist_gdp_list.append(hist_gdp)\n",
    "            max_gdp = gdp(mode='max', task=TASK_TYPE, hist_num=1000, x = x, sens = sens, encoder_model = encoder_model, classifier = classifier)\n",
    "            print('max gdp: ', max_gdp)\n",
    "            max_gdp_list.append(max_gdp)\n",
    "            kernel_gdp = gdp(mode='kernel', task=TASK_TYPE, hist_num=1000, x = x, sens = sens, encoder_model = encoder_model, classifier = classifier)\n",
    "            print('kernel gdp: ', kernel_gdp)\n",
    "            kernel_gdp_list.append(kernel_gdp)\n",
    "            #print(' auc: ', result['auc'], ' dp: ', dp)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):   1%|          | 1/100 [03:00<4:57:30, 180.31s/it, loss=0.642, conditional_loss=0.642, debias_loss=0, adv_loss=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6419667425044115, 'conditional_loss': 0.6419667425044115, 'debias_loss': 0.0, 'adv_loss': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(LR): 100%|██████████| 500/500 [00:04<00:00, best test F1Mi=0.731, F1Ma=0.643]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance:  0.6345626258763142\n",
      "hist gdp:  0.09972800000000001\n",
      "max gdp:  0.2055365946150929\n",
      "kernel gdp:  0.087692186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):   2%|▏         | 2/100 [06:54<5:46:41, 212.26s/it, loss=0.0736, conditional_loss=0.0736, debias_loss=0, adv_loss=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.07356313332540435, 'conditional_loss': 0.07356313332540435, 'debias_loss': 0.0, 'adv_loss': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(LR): 100%|██████████| 500/500 [00:04<00:00, best test F1Mi=0.725, F1Ma=0.631]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance:  0.6238862334309304\n",
      "hist gdp:  0.102008\n",
      "max gdp:  0.2102356102949663\n",
      "kernel gdp:  0.089697026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):   3%|▎         | 3/100 [10:50<6:00:29, 222.98s/it, loss=0.0544, conditional_loss=0.0544, debias_loss=0, adv_loss=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.054353300259454444, 'conditional_loss': 0.054353300259454444, 'debias_loss': 0.0, 'adv_loss': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(LR): 100%|██████████| 500/500 [00:04<00:00, best test F1Mi=0.725, F1Ma=0.63]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance:  0.6231381176116194\n",
      "hist gdp:  0.09635200000000001\n",
      "max gdp:  0.19857875385401727\n",
      "kernel gdp:  0.08472363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):   4%|▍         | 4/100 [14:44<6:03:46, 227.36s/it, loss=0.0478, conditional_loss=0.0478, debias_loss=0, adv_loss=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.047750510638521156, 'conditional_loss': 0.047750510638521156, 'debias_loss': 0.0, 'adv_loss': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(LR): 100%|██████████| 500/500 [00:04<00:00, best test F1Mi=0.726, F1Ma=0.635]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance:  0.6270269867205733\n",
      "hist gdp:  0.10283600000000001\n",
      "max gdp:  0.21194209493660449\n",
      "kernel gdp:  0.0904251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):   5%|▌         | 5/100 [18:39<6:04:00, 229.90s/it, loss=0.0429, conditional_loss=0.0429, debias_loss=0, adv_loss=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.042856269240754204, 'conditional_loss': 0.042856269240754204, 'debias_loss': 0.0, 'adv_loss': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(LR): 100%|██████████| 500/500 [00:04<00:00, best test F1Mi=0.73, F1Ma=0.637]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance:  0.6292773642022135\n",
      "hist gdp:  0.10946000000000002\n",
      "max gdp:  0.22559397206971032\n",
      "kernel gdp:  0.09624967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):   6%|▌         | 6/100 [22:33<6:02:34, 231.44s/it, loss=0.0401, conditional_loss=0.0401, debias_loss=0, adv_loss=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.04007712656151761, 'conditional_loss': 0.04007712656151761, 'debias_loss': 0.0, 'adv_loss': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(LR): 100%|██████████| 500/500 [00:04<00:00, best test F1Mi=0.72, F1Ma=0.628]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance:  0.6216384521635266\n",
      "hist gdp:  0.10911600000000002\n",
      "max gdp:  0.22488499777415044\n",
      "kernel gdp:  0.09594718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):   7%|▋         | 7/100 [26:27<6:00:13, 232.41s/it, loss=0.0378, conditional_loss=0.0378, debias_loss=0, adv_loss=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.03775195900421097, 'conditional_loss': 0.03775195900421097, 'debias_loss': 0.0, 'adv_loss': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(LR): 100%|██████████| 500/500 [00:04<00:00, best test F1Mi=0.72, F1Ma=0.626]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance:  0.6199792751238548\n",
      "hist gdp:  0.10780400000000002\n",
      "max gdp:  0.22218100278643388\n",
      "kernel gdp:  0.09479352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):   8%|▊         | 8/100 [30:22<5:57:23, 233.08s/it, loss=0.0362, conditional_loss=0.0362, debias_loss=0, adv_loss=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.03617247288355475, 'conditional_loss': 0.03617247288355475, 'debias_loss': 0.0, 'adv_loss': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(LR): 100%|██████████| 500/500 [00:04<00:00, best test F1Mi=0.721, F1Ma=0.626]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance:  0.6199317599780478\n",
      "hist gdp:  0.10318\n",
      "max gdp:  0.21265106923216437\n",
      "kernel gdp:  0.090727575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):   9%|▉         | 9/100 [34:16<5:54:06, 233.48s/it, loss=0.0352, conditional_loss=0.0352, debias_loss=0, adv_loss=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.03521631581931369, 'conditional_loss': 0.03521631581931369, 'debias_loss': 0.0, 'adv_loss': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(LR): 100%|██████████| 500/500 [00:04<00:00, best test F1Mi=0.726, F1Ma=0.633]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance:  0.6260286716383043\n",
      "hist gdp:  0.097244\n",
      "max gdp:  0.2004171406901782\n",
      "kernel gdp:  0.085507974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  10%|█         | 10/100 [38:11<5:50:43, 233.81s/it, loss=0.0344, conditional_loss=0.0344, debias_loss=0, adv_loss=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.03437289359551743, 'conditional_loss': 0.03437289359551743, 'debias_loss': 0.0, 'adv_loss': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(LR): 100%|██████████| 500/500 [00:04<00:00, best test F1Mi=0.724, F1Ma=0.629]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance:  0.6224505002236373\n",
      "hist gdp:  0.103524\n",
      "max gdp:  0.21336004352772417\n",
      "kernel gdp:  0.09103006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  11%|█         | 11/100 [42:06<5:47:16, 234.12s/it, loss=0.0332, conditional_loss=0.0332, debias_loss=0, adv_loss=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.03317140449283633, 'conditional_loss': 0.03317140449283633, 'debias_loss': 0.0, 'adv_loss': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(LR): 100%|██████████| 500/500 [00:04<00:00, best test F1Mi=0.723, F1Ma=0.63]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance:  0.6232843476311217\n",
      "hist gdp:  0.100556\n",
      "max gdp:  0.20724307925673116\n",
      "kernel gdp:  0.08842026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  12%|█▏        | 12/100 [46:00<5:43:34, 234.25s/it, loss=0.0326, conditional_loss=0.0326, debias_loss=0, adv_loss=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.032616274407918346, 'conditional_loss': 0.032616274407918346, 'debias_loss': 0.0, 'adv_loss': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(LR): 100%|██████████| 500/500 [00:04<00:00, best test F1Mi=0.719, F1Ma=0.621]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance:  0.6160576490216115\n",
      "hist gdp:  0.098416\n",
      "max gdp:  0.20283259962737626\n",
      "kernel gdp:  0.08653853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  13%|█▎        | 13/100 [49:55<5:39:56, 234.44s/it, loss=0.032, conditional_loss=0.032, debias_loss=0, adv_loss=0]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.032023709454813844, 'conditional_loss': 0.032023709454813844, 'debias_loss': 0.0, 'adv_loss': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(LR): 100%|██████████| 500/500 [00:04<00:00, best test F1Mi=0.72, F1Ma=0.631]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance:  0.6244641794653158\n",
      "hist gdp:  0.102072\n",
      "max gdp:  0.21036751248948904\n",
      "kernel gdp:  0.0897533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  14%|█▍        | 14/100 [53:50<5:36:00, 234.42s/it, loss=0.0314, conditional_loss=0.0314, debias_loss=0, adv_loss=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.031432784426043615, 'conditional_loss': 0.031432784426043615, 'debias_loss': 0.0, 'adv_loss': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(LR): 100%|██████████| 500/500 [00:04<00:00, best test F1Mi=0.722, F1Ma=0.627]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance:  0.6201128149864011\n",
      "hist gdp:  0.099244\n",
      "max gdp:  0.20453908426901452\n",
      "kernel gdp:  0.0872666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  15%|█▌        | 15/100 [57:45<5:32:33, 234.74s/it, loss=0.0309, conditional_loss=0.0309, debias_loss=0, adv_loss=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.030886147305978544, 'conditional_loss': 0.030886147305978544, 'debias_loss': 0.0, 'adv_loss': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(LR): 100%|██████████| 500/500 [00:04<00:00, best test F1Mi=0.725, F1Ma=0.636]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance:  0.6289900008124942\n",
      "hist gdp:  0.10986800000000001\n",
      "max gdp:  0.2264348485597929\n",
      "kernel gdp:  0.09660842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  16%|█▌        | 16/100 [1:01:40<5:28:33, 234.68s/it, loss=0.0305, conditional_loss=0.0305, debias_loss=0, adv_loss=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.030499808267696098, 'conditional_loss': 0.030499808267696098, 'debias_loss': 0.0, 'adv_loss': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(LR): 100%|██████████| 500/500 [00:04<00:00, best test F1Mi=0.727, F1Ma=0.631]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance:  0.623555266749205\n",
      "hist gdp:  0.103932\n",
      "max gdp:  0.2142009200178068\n",
      "kernel gdp:  0.09138882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  17%|█▋        | 17/100 [1:05:34<5:24:38, 234.68s/it, loss=0.0302, conditional_loss=0.0302, debias_loss=0, adv_loss=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.030191128101176436, 'conditional_loss': 0.030191128101176436, 'debias_loss': 0.0, 'adv_loss': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(LR): 100%|██████████| 500/500 [00:04<00:00, best test F1Mi=0.719, F1Ma=0.625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance:  0.6193855314566479\n",
      "hist gdp:  0.10904\n",
      "max gdp:  0.2247283639181547\n",
      "kernel gdp:  0.09588035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  18%|█▊        | 18/100 [1:09:29<5:20:48, 234.74s/it, loss=0.0299, conditional_loss=0.0299, debias_loss=0, adv_loss=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.02990869219479321, 'conditional_loss': 0.02990869219479321, 'debias_loss': 0.0, 'adv_loss': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(LR): 100%|██████████| 500/500 [00:04<00:00, best test F1Mi=0.723, F1Ma=0.624]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance:  0.6182473169254863\n",
      "hist gdp:  0.09944799999999998\n",
      "max gdp:  0.20495952251405583\n",
      "kernel gdp:  0.087445974\n"
     ]
    }
   ],
   "source": [
    "# F F F\n",
    "contrast_model = DualBranchContrast(loss=L.FairInfoNCE(tau=config['tau']), mode='G2G').to(device)\n",
    "optim = Adam(encoder_model.parameters(), lr=config['lr'])\n",
    "\n",
    "performance_list = []\n",
    "hist_gdp_list = []\n",
    "max_gdp_list = []\n",
    "kernel_gdp_list = []\n",
    "\n",
    "epoch = 100\n",
    "with tqdm(total=epoch, desc='(T)') as pbar:\n",
    "    for epoch in range(1, epoch+1):\n",
    "        encoder_model = encoder_model.to(device)\n",
    "        loss_result = train(encoder_model = encoder_model, contrast_model=contrast_model,\n",
    "                                         dataloader=dataloader, optimizer = optim,\n",
    "                                         conditional=config['conditional'],debias=config['debias'], adversarial=config['adversarial'] if epoch%5==0 else False,\n",
    "                                         cond_temp = config['cond_temp'],\n",
    "                                         debias_temp = config['debias_temp'],\n",
    "                                         debias_ratio = config['debias_ratio'])\n",
    "        pbar.set_postfix({'loss': loss_result['loss'], \n",
    "                          'conditional_loss':loss_result['conditional_loss'], \n",
    "                          'debias_loss': loss_result['debias_loss'],\n",
    "                          'adv_loss': loss_result['adv_loss']})\n",
    "        pbar.update()\n",
    "        \n",
    "        if epoch % 1 == 0:\n",
    "            print(loss_result)\n",
    "            result, evaluator = test(encoder_model, dataloader, evaluator=LREvaluator(task=TASK_TYPE))\n",
    "            classifier = result['classifier']\n",
    "            \n",
    "            # performance \n",
    "            performance = result['mae'] if dataset_name=='crimes' else result['auc']\n",
    "            print('performance: ', performance)\n",
    "            performance_list.append(performance)\n",
    "\n",
    "            # fairness\n",
    "            hist_gdp = gdp(mode='hist', task=TASK_TYPE, hist_num=1000, x = x, sens = sens, encoder_model = encoder_model, classifier = classifier)\n",
    "            print('hist gdp: ', hist_gdp)\n",
    "            hist_gdp_list.append(hist_gdp)\n",
    "            max_gdp = gdp(mode='max', task=TASK_TYPE, hist_num=1000, x = x, sens = sens, encoder_model = encoder_model, classifier = classifier)\n",
    "            print('max gdp: ', max_gdp)\n",
    "            max_gdp_list.append(max_gdp)\n",
    "            kernel_gdp = gdp(mode='kernel', task=TASK_TYPE, hist_num=1000, x = x, sens = sens, encoder_model = encoder_model, classifier = classifier)\n",
    "            print('kernel gdp: ', kernel_gdp)\n",
    "            kernel_gdp_list.append(kernel_gdp)\n",
    "            #print(' auc: ', result['auc'], ' dp: ', dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function data_util.load_pokec(dataset, sens_attr, predict_attr, path='../dataset/pokec/', sens_number=500, seed=19, test_idx=False)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_pokec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading region_job dataset from ./datasets/pokec/\n"
     ]
    }
   ],
   "source": [
    "dataset = 'region_job'\n",
    "sens_attr = 'region' # AGE\n",
    "predict_attr = 'I_am_working_in_field'#'spoken_languages_indicator'\n",
    "path=\"./datasets/pokec/\"\n",
    "sens_number=500\n",
    "seed=19\n",
    "test_idx=False\n",
    "import scipy.sparse as sp\n",
    "print('Loading {} dataset from {}'.format(dataset,path))\n",
    "\n",
    "idx_features_labels = pd.read_csv(os.path.join(path,\"{}.csv\".format(dataset)))\n",
    "header = list(idx_features_labels.columns)\n",
    "header.remove(\"user_id\")\n",
    "\n",
    "header.remove(sens_attr)\n",
    "header.remove(predict_attr)\n",
    "\n",
    "\n",
    "features = sp.csr_matrix(idx_features_labels[header], dtype=np.float32)\n",
    "labels = idx_features_labels[predict_attr].values\n",
    "\n",
    "\n",
    "# build graph\n",
    "idx = np.array(idx_features_labels[\"user_id\"], dtype=int)\n",
    "idx_map = {j: i for i, j in enumerate(idx)}\n",
    "edges_unordered = np.genfromtxt(os.path.join(path,\"{}_relationship.txt\".format(dataset)), dtype=int)\n",
    "\n",
    "edges = np.array(list(map(idx_map.get, edges_unordered.flatten())),\n",
    "                    dtype=int).reshape(edges_unordered.shape)\n",
    "adj = sp.coo_matrix((np.ones(edges.shape[0]), (edges[:, 0], edges[:, 1])),\n",
    "                    shape=(labels.shape[0], labels.shape[0]),\n",
    "                    dtype=np.float32)\n",
    "# build symmetric adjacency matrix\n",
    "adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)\n",
    "\n",
    "# features = normalize(features)\n",
    "adj = adj + sp.eye(adj.shape[0])\n",
    "\n",
    "features = torch.FloatTensor(np.array(features.todense()))\n",
    "labels = torch.LongTensor(labels)\n",
    "# adj = sparse_mx_to_torch_sparse_tensor(adj)\n",
    "\n",
    "import random\n",
    "random.seed(seed)\n",
    "label_idx = np.where(labels>=0)[0]\n",
    "random.shuffle(label_idx)\n",
    "\n",
    "idx_train = label_idx[:int(0.5 * len(label_idx))]\n",
    "idx_val = label_idx[int(0.5 * len(label_idx)):int(0.75 * len(label_idx))]\n",
    "if test_idx:\n",
    "    idx_test = label_idx[int(0.5 * len(label_idx)):]\n",
    "    idx_val = idx_test\n",
    "else:\n",
    "    idx_test = label_idx[int(0.75 * len(label_idx)):]\n",
    "\n",
    "sens = idx_features_labels[sens_attr].values\n",
    "\n",
    "sens_idx = set(np.where(sens >= 0)[0])\n",
    "idx_test = np.asarray(list(sens_idx & set(idx_test)))\n",
    "sens = torch.FloatTensor(sens)\n",
    "idx_sens_train = list(sens_idx - set(idx_val) - set(idx_test))\n",
    "random.seed(seed)\n",
    "random.shuffle(idx_sens_train)\n",
    "idx_sens_train = torch.LongTensor(idx_sens_train[:sens_number])\n",
    "\n",
    "\n",
    "idx_train = torch.LongTensor(idx_train)\n",
    "idx_val = torch.LongTensor(idx_val)\n",
    "idx_test = torch.LongTensor(idx_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([67796])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([43962.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0., 23834.]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ],\n",
       "       dtype=float32),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.hist(sens.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dgl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/data/qf31/FCL/nothing.ipynb Cell 12'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bdatalab2/data/qf31/FCL/nothing.ipynb#ch0000014vscode-remote?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mdgl\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdatalab2/data/qf31/FCL/nothing.ipynb#ch0000014vscode-remote?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m feature_norm\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdatalab2/data/qf31/FCL/nothing.ipynb#ch0000014vscode-remote?line=2'>3</a>\u001b[0m \u001b[39m# g = dgl.DGLGraph()\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dgl'"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "from utils import feature_norm\n",
    "# g = dgl.DGLGraph()\n",
    "g = dgl.from_scipy(adj)\n",
    "g = g.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mType:\u001b[0m        ndarray\n",
      "\u001b[0;31mString form:\u001b[0m [15836 41916  8624 ... 67042 15818  5669]\n",
      "\u001b[0;31mLength:\u001b[0m      67796\n",
      "\u001b[0;31mFile:\u001b[0m        /data/qf31/anaconda3/envs/graph/lib/python3.9/site-packages/numpy/__init__.py\n",
      "\u001b[0;31mDocstring:\u001b[0m  \n",
      "ndarray(shape, dtype=float, buffer=None, offset=0,\n",
      "        strides=None, order=None)\n",
      "\n",
      "An array object represents a multidimensional, homogeneous array\n",
      "of fixed-size items.  An associated data-type object describes the\n",
      "format of each element in the array (its byte-order, how many bytes it\n",
      "occupies in memory, whether it is an integer, a floating point number,\n",
      "or something else, etc.)\n",
      "\n",
      "Arrays should be constructed using `array`, `zeros` or `empty` (refer\n",
      "to the See Also section below).  The parameters given here refer to\n",
      "a low-level method (`ndarray(...)`) for instantiating an array.\n",
      "\n",
      "For more information, refer to the `numpy` module and examine the\n",
      "methods and attributes of an array.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "(for the __new__ method; see Notes below)\n",
      "\n",
      "shape : tuple of ints\n",
      "    Shape of created array.\n",
      "dtype : data-type, optional\n",
      "    Any object that can be interpreted as a numpy data type.\n",
      "buffer : object exposing buffer interface, optional\n",
      "    Used to fill the array with data.\n",
      "offset : int, optional\n",
      "    Offset of array data in buffer.\n",
      "strides : tuple of ints, optional\n",
      "    Strides of data in memory.\n",
      "order : {'C', 'F'}, optional\n",
      "    Row-major (C-style) or column-major (Fortran-style) order.\n",
      "\n",
      "Attributes\n",
      "----------\n",
      "T : ndarray\n",
      "    Transpose of the array.\n",
      "data : buffer\n",
      "    The array's elements, in memory.\n",
      "dtype : dtype object\n",
      "    Describes the format of the elements in the array.\n",
      "flags : dict\n",
      "    Dictionary containing information related to memory use, e.g.,\n",
      "    'C_CONTIGUOUS', 'OWNDATA', 'WRITEABLE', etc.\n",
      "flat : numpy.flatiter object\n",
      "    Flattened version of the array as an iterator.  The iterator\n",
      "    allows assignments, e.g., ``x.flat = 3`` (See `ndarray.flat` for\n",
      "    assignment examples; TODO).\n",
      "imag : ndarray\n",
      "    Imaginary part of the array.\n",
      "real : ndarray\n",
      "    Real part of the array.\n",
      "size : int\n",
      "    Number of elements in the array.\n",
      "itemsize : int\n",
      "    The memory use of each array element in bytes.\n",
      "nbytes : int\n",
      "    The total number of bytes required to store the array data,\n",
      "    i.e., ``itemsize * size``.\n",
      "ndim : int\n",
      "    The array's number of dimensions.\n",
      "shape : tuple of ints\n",
      "    Shape of the array.\n",
      "strides : tuple of ints\n",
      "    The step-size required to move from one element to the next in\n",
      "    memory. For example, a contiguous ``(3, 4)`` array of type\n",
      "    ``int16`` in C-order has strides ``(8, 2)``.  This implies that\n",
      "    to move from element to element in memory requires jumps of 2 bytes.\n",
      "    To move from row-to-row, one needs to jump 8 bytes at a time\n",
      "    (``2 * 4``).\n",
      "ctypes : ctypes object\n",
      "    Class containing properties of the array needed for interaction\n",
      "    with ctypes.\n",
      "base : ndarray\n",
      "    If the array is a view into another array, that array is its `base`\n",
      "    (unless that array is also a view).  The `base` array is where the\n",
      "    array data is actually stored.\n",
      "\n",
      "See Also\n",
      "--------\n",
      "array : Construct an array.\n",
      "zeros : Create an array, each element of which is zero.\n",
      "empty : Create an array, but leave its allocated memory unchanged (i.e.,\n",
      "        it contains \"garbage\").\n",
      "dtype : Create a data-type.\n",
      "numpy.typing.NDArray : A :term:`generic <generic type>` version\n",
      "                       of ndarray.\n",
      "\n",
      "Notes\n",
      "-----\n",
      "There are two modes of creating an array using ``__new__``:\n",
      "\n",
      "1. If `buffer` is None, then only `shape`, `dtype`, and `order`\n",
      "   are used.\n",
      "2. If `buffer` is an object exposing the buffer interface, then\n",
      "   all keywords are interpreted.\n",
      "\n",
      "No ``__init__`` method is needed because the array is fully initialized\n",
      "after the ``__new__`` method.\n",
      "\n",
      "Examples\n",
      "--------\n",
      "These examples illustrate the low-level `ndarray` constructor.  Refer\n",
      "to the `See Also` section above for easier ways of constructing an\n",
      "ndarray.\n",
      "\n",
      "First mode, `buffer` is None:\n",
      "\n",
      ">>> np.ndarray(shape=(2,2), dtype=float, order='F')\n",
      "array([[0.0e+000, 0.0e+000], # random\n",
      "       [     nan, 2.5e-323]])\n",
      "\n",
      "Second mode:\n",
      "\n",
      ">>> np.ndarray((2,), buffer=np.array([1,2,3]),\n",
      "...            offset=np.int_().itemsize,\n",
      "...            dtype=int) # offset = 1*itemsize, i.e. skip first element\n",
      "array([2, 3])\n"
     ]
    }
   ],
   "source": [
    "label_idx?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mType:\u001b[0m        Tensor\n",
      "\u001b[0;31mString form:\u001b[0m tensor([1, 1, 1,  ..., 0, 0, 0])\n",
      "\u001b[0;31mLength:\u001b[0m      67796\n",
      "\u001b[0;31mFile:\u001b[0m        /data/qf31/anaconda3/envs/graph/lib/python3.9/site-packages/torch/__init__.py\n",
      "\u001b[0;31mDocstring:\u001b[0m   <no docstring>\n"
     ]
    }
   ],
   "source": [
    "labels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mType:\u001b[0m        ndarray\n",
      "\u001b[0;31mString form:\u001b[0m [      1  131075       5 ... 1572853 1572859  393212]\n",
      "\u001b[0;31mLength:\u001b[0m      67796\n",
      "\u001b[0;31mFile:\u001b[0m        /data/qf31/anaconda3/envs/graph/lib/python3.9/site-packages/numpy/__init__.py\n",
      "\u001b[0;31mDocstring:\u001b[0m  \n",
      "ndarray(shape, dtype=float, buffer=None, offset=0,\n",
      "        strides=None, order=None)\n",
      "\n",
      "An array object represents a multidimensional, homogeneous array\n",
      "of fixed-size items.  An associated data-type object describes the\n",
      "format of each element in the array (its byte-order, how many bytes it\n",
      "occupies in memory, whether it is an integer, a floating point number,\n",
      "or something else, etc.)\n",
      "\n",
      "Arrays should be constructed using `array`, `zeros` or `empty` (refer\n",
      "to the See Also section below).  The parameters given here refer to\n",
      "a low-level method (`ndarray(...)`) for instantiating an array.\n",
      "\n",
      "For more information, refer to the `numpy` module and examine the\n",
      "methods and attributes of an array.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "(for the __new__ method; see Notes below)\n",
      "\n",
      "shape : tuple of ints\n",
      "    Shape of created array.\n",
      "dtype : data-type, optional\n",
      "    Any object that can be interpreted as a numpy data type.\n",
      "buffer : object exposing buffer interface, optional\n",
      "    Used to fill the array with data.\n",
      "offset : int, optional\n",
      "    Offset of array data in buffer.\n",
      "strides : tuple of ints, optional\n",
      "    Strides of data in memory.\n",
      "order : {'C', 'F'}, optional\n",
      "    Row-major (C-style) or column-major (Fortran-style) order.\n",
      "\n",
      "Attributes\n",
      "----------\n",
      "T : ndarray\n",
      "    Transpose of the array.\n",
      "data : buffer\n",
      "    The array's elements, in memory.\n",
      "dtype : dtype object\n",
      "    Describes the format of the elements in the array.\n",
      "flags : dict\n",
      "    Dictionary containing information related to memory use, e.g.,\n",
      "    'C_CONTIGUOUS', 'OWNDATA', 'WRITEABLE', etc.\n",
      "flat : numpy.flatiter object\n",
      "    Flattened version of the array as an iterator.  The iterator\n",
      "    allows assignments, e.g., ``x.flat = 3`` (See `ndarray.flat` for\n",
      "    assignment examples; TODO).\n",
      "imag : ndarray\n",
      "    Imaginary part of the array.\n",
      "real : ndarray\n",
      "    Real part of the array.\n",
      "size : int\n",
      "    Number of elements in the array.\n",
      "itemsize : int\n",
      "    The memory use of each array element in bytes.\n",
      "nbytes : int\n",
      "    The total number of bytes required to store the array data,\n",
      "    i.e., ``itemsize * size``.\n",
      "ndim : int\n",
      "    The array's number of dimensions.\n",
      "shape : tuple of ints\n",
      "    Shape of the array.\n",
      "strides : tuple of ints\n",
      "    The step-size required to move from one element to the next in\n",
      "    memory. For example, a contiguous ``(3, 4)`` array of type\n",
      "    ``int16`` in C-order has strides ``(8, 2)``.  This implies that\n",
      "    to move from element to element in memory requires jumps of 2 bytes.\n",
      "    To move from row-to-row, one needs to jump 8 bytes at a time\n",
      "    (``2 * 4``).\n",
      "ctypes : ctypes object\n",
      "    Class containing properties of the array needed for interaction\n",
      "    with ctypes.\n",
      "base : ndarray\n",
      "    If the array is a view into another array, that array is its `base`\n",
      "    (unless that array is also a view).  The `base` array is where the\n",
      "    array data is actually stored.\n",
      "\n",
      "See Also\n",
      "--------\n",
      "array : Construct an array.\n",
      "zeros : Create an array, each element of which is zero.\n",
      "empty : Create an array, but leave its allocated memory unchanged (i.e.,\n",
      "        it contains \"garbage\").\n",
      "dtype : Create a data-type.\n",
      "numpy.typing.NDArray : A :term:`generic <generic type>` version\n",
      "                       of ndarray.\n",
      "\n",
      "Notes\n",
      "-----\n",
      "There are two modes of creating an array using ``__new__``:\n",
      "\n",
      "1. If `buffer` is None, then only `shape`, `dtype`, and `order`\n",
      "   are used.\n",
      "2. If `buffer` is an object exposing the buffer interface, then\n",
      "   all keywords are interpreted.\n",
      "\n",
      "No ``__init__`` method is needed because the array is fully initialized\n",
      "after the ``__new__`` method.\n",
      "\n",
      "Examples\n",
      "--------\n",
      "These examples illustrate the low-level `ndarray` constructor.  Refer\n",
      "to the `See Also` section above for easier ways of constructing an\n",
      "ndarray.\n",
      "\n",
      "First mode, `buffer` is None:\n",
      "\n",
      ">>> np.ndarray(shape=(2,2), dtype=float, order='F')\n",
      "array([[0.0e+000, 0.0e+000], # random\n",
      "       [     nan, 2.5e-323]])\n",
      "\n",
      "Second mode:\n",
      "\n",
      ">>> np.ndarray((2,), buffer=np.array([1,2,3]),\n",
      "...            offset=np.int_().itemsize,\n",
      "...            dtype=int) # offset = 1*itemsize, i.e. skip first element\n",
      "array([2, 3])\n"
     ]
    }
   ],
   "source": [
    "idx?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "abfb1acfa98d0a33cb94187767224d1f136be213a9bbe77ab333b00a77a72f44"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('graph': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
